\BOOKMARK [1][-]{section.1}{张量概述}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{创建}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{张量属性}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{与numpy互操作}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{张量操作}{section.1}% 5
\BOOKMARK [3][-]{subsubsection.1.4.1}{改变形状}{subsection.1.4}% 6
\BOOKMARK [3][-]{subsubsection.1.4.2}{元素操作}{subsection.1.4}% 7
\BOOKMARK [3][-]{subsubsection.1.4.3}{Reduction}{subsection.1.4}% 8
\BOOKMARK [3][-]{subsubsection.1.4.4}{索引和切片}{subsection.1.4}% 9
\BOOKMARK [2][-]{subsection.1.5}{张量底层原理}{section.1}% 10
\BOOKMARK [2][-]{subsection.1.6}{总结}{section.1}% 11
\BOOKMARK [1][-]{section.2}{自动微分概述}{}% 12
\BOOKMARK [2][-]{subsection.2.1}{数学原理}{section.2}% 13
\BOOKMARK [3][-]{subsubsection.2.1.1}{函数以张量为参数}{subsection.2.1}% 14
\BOOKMARK [3][-]{subsubsection.2.1.2}{标量对向量微分}{subsection.2.1}% 15
\BOOKMARK [3][-]{subsubsection.2.1.3}{向量对向量微分}{subsection.2.1}% 16
\BOOKMARK [3][-]{subsubsection.2.1.4}{向量对矩阵微分}{subsection.2.1}% 17
\BOOKMARK [2][-]{subsection.2.2}{自动微分求解线性回归}{section.2}% 18
\BOOKMARK [3][-]{subsubsection.2.2.1}{使用numpy库}{subsection.2.2}% 19
\BOOKMARK [3][-]{subsubsection.2.2.2}{使用PyTorch}{subsection.2.2}% 20
\BOOKMARK [2][-]{subsection.2.3}{总结}{section.2}% 21
\BOOKMARK [1][-]{section.3}{线性回归概述}{}% 22
\BOOKMARK [2][-]{subsection.3.1}{数学原理}{section.3}% 23
\BOOKMARK [3][-]{subsubsection.3.1.1}{迭代法求解}{subsection.3.1}% 24
\BOOKMARK [3][-]{subsubsection.3.1.2}{解析法求解}{subsection.3.1}% 25
\BOOKMARK [2][-]{subsection.3.2}{线性回归求解}{section.3}% 26
\BOOKMARK [2][-]{subsection.3.3}{多项式回归}{section.3}% 27
\BOOKMARK [2][-]{subsection.3.4}{总结}{section.3}% 28
\BOOKMARK [1][-]{section.4}{逻辑回归概述}{}% 29
\BOOKMARK [2][-]{subsection.4.1}{数学基础}{section.4}% 30
\BOOKMARK [3][-]{subsubsection.4.1.1}{直观解释}{subsection.4.1}% 31
\BOOKMARK [3][-]{subsubsection.4.1.2}{数学推导}{subsection.4.1}% 32
\BOOKMARK [3][-]{subsubsection.4.1.3}{牛顿法}{subsection.4.1}% 33
\BOOKMARK [3][-]{subsubsection.4.1.4}{通用学习模型}{subsection.4.1}% 34
\BOOKMARK [3][-]{subsubsection.4.1.5}{交叉熵函数}{subsection.4.1}% 35
\BOOKMARK [2][-]{subsection.4.2}{二分类问题应用}{section.4}% 36
\BOOKMARK [2][-]{subsection.4.3}{softmax回归应用}{section.4}% 37
\BOOKMARK [3][-]{subsubsection.4.3.1}{载入MNIST数据集}{subsection.4.3}% 38
\BOOKMARK [3][-]{subsubsection.4.3.2}{MNIST数据集可视化}{subsection.4.3}% 39
\BOOKMARK [3][-]{subsubsection.4.3.3}{代码实现}{subsection.4.3}% 40
\BOOKMARK [2][-]{subsection.4.4}{总结}{section.4}% 41
\BOOKMARK [1][-]{section.5}{多层感知器（MLP）概述}{}% 42
\BOOKMARK [2][-]{subsection.5.1}{数学原理}{section.5}% 43
\BOOKMARK [3][-]{subsubsection.5.1.1}{前向传播过程}{subsection.5.1}% 44
\BOOKMARK [3][-]{subsubsection.5.1.2}{神经元激活函数}{subsection.5.1}% 45
\BOOKMARK [3][-]{subsubsection.5.1.3}{深度学习中的微分运算}{subsection.5.1}% 46
\BOOKMARK [3][-]{subsubsection.5.1.4}{softmax和Cross Entropy}{subsection.5.1}% 47
\BOOKMARK [3][-]{subsubsection.5.1.5}{计算图简介}{subsection.5.1}% 48
\BOOKMARK [3][-]{subsubsection.5.1.6}{Softmax层实现技术}{subsection.5.1}% 49
\BOOKMARK [3][-]{subsubsection.5.1.7}{ReLU层实现技术}{subsection.5.1}% 50
\BOOKMARK [2][-]{subsection.5.2}{Numpy实现技术}{section.5}% 51
\BOOKMARK [3][-]{subsubsection.5.2.1}{MNIST数据集简介}{subsection.5.2}% 52
\BOOKMARK [3][-]{subsubsection.5.2.2}{应用入口}{subsection.5.2}% 53
\BOOKMARK [3][-]{subsubsection.5.2.3}{多层感知器类}{subsection.5.2}% 54
\BOOKMARK [3][-]{subsubsection.5.2.4}{神经网络层定义}{subsection.5.2}% 55
\BOOKMARK [3][-]{subsubsection.5.2.5}{优化器}{subsection.5.2}% 56
\BOOKMARK [3][-]{subsubsection.5.2.6}{训练过程}{subsection.5.2}% 57
\BOOKMARK [3][-]{subsubsection.5.2.7}{预测过程}{subsection.5.2}% 58
\BOOKMARK [2][-]{subsection.5.3}{PyTorch方法}{section.5}% 59
\BOOKMARK [3][-]{subsubsection.5.3.1}{载入数据集}{subsection.5.3}% 60
\BOOKMARK [3][-]{subsubsection.5.3.2}{模型定义}{subsection.5.3}% 61
\BOOKMARK [3][-]{subsubsection.5.3.3}{训练和预测过程}{subsection.5.3}% 62
\BOOKMARK [2][-]{subsection.5.4}{PyTorch核心原理}{section.5}% 63
\BOOKMARK [3][-]{subsubsection.5.4.1}{载入数据集}{subsection.5.4}% 64
\BOOKMARK [1][-]{section.6}{卷积神经网络概述}{}% 65
\BOOKMARK [1][-]{section.7}{递归神经网络概述}{}% 66

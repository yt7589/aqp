\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{pytorch-tensor-intro}
\citation{csdn-blog-my-tensor1}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}张量概述}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}创建}{1}{subsection.1.1}}
\newlabel{tensor-create-tensor}{{1}{1}{创建张量（app.pytorch.book.chp001.chp001\_c001.py）\relax }{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}创建张量（app.pytorch.book.chp001.chp001\_c001.py）}{1}{lstlisting.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 创建张量（Tensor）运行结果\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{f000001}{{1}{2}{创建张量（Tensor）运行结果\relax \relax }{figure.caption.2}{}}
\newlabel{tensor-tensor-attribute}{{2}{3}{张量基本属性（app.pytorch.book.chp001.chp001\_c001.py）\relax }{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}张量基本属性（app.pytorch.book.chp001.chp001\_c001.py）}{3}{lstlisting.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 张量基本属性（Tensor）运行结果\relax }}{3}{figure.caption.3}}
\newlabel{f000002}{{2}{3}{张量基本属性（Tensor）运行结果\relax \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}张量属性}{3}{subsection.1.2}}
\newlabel{tensor-tensor-properties}{{3}{3}{张量基本属性（app.pytorch.book.chp001.chp001\_c002.py）\relax }{lstlisting.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}张量基本属性（app.pytorch.book.chp001.chp001\_c002.py）}{3}{lstlisting.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 张量性质（Tensor）运行结果\relax }}{4}{figure.caption.4}}
\newlabel{f000003}{{3}{4}{张量性质（Tensor）运行结果\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}与numpy互操作}{4}{subsection.1.3}}
\newlabel{tensor-tensor-numpy}{{4}{4}{tensor和numpy互操作（app.pytorch.book.chp001.chp001\_c003.py）\relax }{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}tensor和numpy互操作（app.pytorch.book.chp001.chp001\_c003.py）}{4}{lstlisting.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces tensor和numpy互操作运行结果\relax }}{5}{figure.caption.5}}
\newlabel{f000004}{{4}{5}{tensor和numpy互操作运行结果\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}张量操作}{5}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}改变形状}{5}{subsubsection.1.4.1}}
\newlabel{tensor-tensor-reshape}{{5}{5}{张量形状和变形（app.pytorch.book.chp001.chp001\_c004.py）\relax }{lstlisting.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}张量形状和变形（app.pytorch.book.chp001.chp001\_c004.py）}{5}{lstlisting.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 张量形状及变形\relax }}{6}{figure.caption.6}}
\newlabel{f000005}{{5}{6}{张量形状及变形\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}元素操作}{7}{subsubsection.1.4.2}}
\newlabel{tensor-tensor-elementwise-operation}{{6}{7}{张量元素运算（app.pytorch.book.chp001.chp001\_c005.py）\relax }{lstlisting.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}张量元素运算（app.pytorch.book.chp001.chp001\_c005.py）}{7}{lstlisting.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 张量元素运算运行结果\relax }}{9}{figure.caption.7}}
\newlabel{f000006}{{6}{9}{张量元素运算运行结果\relax \relax }{figure.caption.7}{}}
\newlabel{tensor-scala-broadcast-scala}{{1}{9}{元素操作\relax }{equation.1.1}{}}
\newlabel{tensor-scala-broadcast-tensor}{{2}{10}{元素操作\relax }{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Reduction}{10}{subsubsection.1.4.3}}
\newlabel{tensor-tensor-reduction-operation}{{7}{10}{张量Reduction（app.pytorch.book.chp001.chp001\_c006.py）\relax }{lstlisting.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}张量Reduction（app.pytorch.book.chp001.chp001\_c006.py）}{10}{lstlisting.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces 张量Reduction运算运行结果\relax }}{10}{figure.caption.8}}
\newlabel{f000007}{{7}{10}{张量Reduction运算运行结果\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}索引和切片}{11}{subsubsection.1.4.4}}
\newlabel{tensor-tensor-reduction-operation}{{8}{11}{张量索引和切片（app.pytorch.book.chp001.chp001\_c007.py）\relax }{lstlisting.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}张量索引和切片（app.pytorch.book.chp001.chp001\_c007.py）}{11}{lstlisting.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces 张量索引和切片运算运行结果\relax }}{11}{figure.caption.9}}
\newlabel{f000008}{{8}{11}{张量索引和切片运算运行结果\relax \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}张量底层原理}{12}{subsection.1.5}}
\newlabel{tensor-python-list}{{9}{12}{Python列表\relax }{lstlisting.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}Python列表}{12}{lstlisting.9}}
\citation{deep-learning-with-pytorch}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Python列表内存存储\relax }}{13}{figure.caption.10}}
\newlabel{f000009}{{9}{13}{Python列表内存存储\relax \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces PyTorch张量存储\relax }}{13}{figure.caption.11}}
\newlabel{f000010}{{10}{13}{PyTorch张量存储\relax \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}总结}{14}{subsection.1.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}自动微分概述}{15}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}数学原理}{15}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}函数以张量为参数}{15}{subsubsection.2.1.1}}
\newlabel{autodif-tensor-1}{{3}{15}{函数以张量为参数\relax }{equation.2.3}{}}
\newlabel{autodiff-x2-param-tensor}{{10}{15}{求$x^{2}$函数以张量为参数\relax }{lstlisting.10}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {10}求$x^{2}$函数以张量为参数}{15}{lstlisting.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}标量对向量微分}{15}{subsubsection.2.1.2}}
\newlabel{autodif-func-param-tensor-1}{{4}{15}{标量对向量微分\relax }{equation.2.4}{}}
\newlabel{autodif-func-param-tensor-1-gradient}{{5}{16}{标量对向量微分\relax }{equation.2.5}{}}
\newlabel{autodif-scalar-vector-gradient-def}{{6}{16}{标量对向量微分\relax }{equation.2.6}{}}
\newlabel{autodiff-scalar-vector-gradient-python}{{11}{16}{标量对向量微分实现\relax }{lstlisting.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {11}标量对向量微分实现}{16}{lstlisting.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}向量对向量微分}{16}{subsubsection.2.1.3}}
\newlabel{autodif-vector-vector-gradient-def}{{7}{16}{向量对向量微分\relax }{equation.2.7}{}}
\newlabel{autodif-z-l}{{8}{16}{向量对向量微分\relax }{equation.2.8}{}}
\newlabel{autodif-a-l}{{9}{16}{向量对向量微分\relax }{equation.2.9}{}}
\newlabel{autodif-vector-vector-gradient-demo}{{10}{17}{向量对向量微分\relax }{equation.2.10}{}}
\newlabel{autodif-vector-vector-gradient-simplify}{{11}{17}{向量对向量微分\relax }{equation.2.11}{}}
\newlabel{autodiff-vector-vector-gradient-python}{{12}{17}{向量对向量微分实现\relax }{lstlisting.12}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {12}向量对向量微分实现}{17}{lstlisting.12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}向量对矩阵微分}{17}{subsubsection.2.1.4}}
\newlabel{autodif-neural-network-layer-formula}{{12}{17}{向量对矩阵微分\relax }{equation.2.12}{}}
\newlabel{autodif-neural-network-layer-W-gradient}{{13}{17}{向量对矩阵微分\relax }{equation.2.13}{}}
\newlabel{autodiff-vector-matrix-gradient-python}{{13}{17}{向量对矩阵微分实现\relax }{lstlisting.13}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {13}向量对矩阵微分实现}{17}{lstlisting.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}自动微分求解线性回归}{18}{subsection.2.2}}
\newlabel{autodiff-linear-regression-dataset}{{14}{18}{生成线性回归数据集\relax }{lstlisting.14}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {14}生成线性回归数据集}{18}{lstlisting.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces 线性回归数据集\relax }}{19}{figure.caption.12}}
\newlabel{f000011}{{11}{19}{线性回归数据集\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}使用numpy库}{19}{subsubsection.2.2.1}}
\newlabel{autodiff-linear-regression-numpy}{{15}{19}{numpy求解线性回归问题代码\relax }{lstlisting.15}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {15}numpy求解线性回归问题代码}{19}{lstlisting.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces numpy求解线性回归问题运行结果\relax }}{21}{figure.caption.13}}
\newlabel{f000012}{{12}{21}{numpy求解线性回归问题运行结果\relax \relax }{figure.caption.13}{}}
\newlabel{autodiff-numpy-mse-gradient}{{14}{22}{使用numpy库\relax }{equation.2.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}使用PyTorch}{22}{subsubsection.2.2.2}}
\newlabel{autodiff-linear-regression-pytorch}{{16}{22}{PyTorch求解线性回归问题代码\relax }{lstlisting.16}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {16}PyTorch求解线性回归问题代码}{22}{lstlisting.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces PyTorch求解线性回归问题运行结果\relax }}{24}{figure.caption.14}}
\newlabel{f000013}{{13}{24}{PyTorch求解线性回归问题运行结果\relax \relax }{figure.caption.14}{}}
\newlabel{autodiff-pytorch-mse-gradient}{{15}{24}{使用PyTorch\relax }{equation.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}总结}{24}{subsection.2.3}}
\citation{dl-tf-theano}
\@writefile{toc}{\contentsline {section}{\numberline {3}线性回归概述}{26}{section.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 线性回归问题数据集\relax }}{26}{table.caption.15}}
\newlabel{lrrn-dataset1}{{1}{26}{线性回归问题数据集\relax \relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}数学原理}{26}{subsection.3.1}}
\newlabel{lrrn-x-def}{{16}{26}{数学原理\relax }{equation.3.16}{}}
\newlabel{lrrn-linear-function-def}{{17}{26}{数学原理\relax }{equation.3.17}{}}
\newlabel{lrrn-linear-function-expand}{{18}{26}{数学原理\relax }{equation.3.18}{}}
\newlabel{lrrn-linear-regression-loss-i}{{19}{27}{数学原理\relax }{equation.3.19}{}}
\newlabel{lrrn-linear-regression-loss}{{20}{27}{数学原理\relax }{equation.3.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}迭代法求解}{27}{subsubsection.3.1.1}}
\newlabel{lrrn-loss-gradient-samplei-thetaj}{{21}{27}{迭代法求解\relax }{equation.3.21}{}}
\newlabel{lrrn-loss-gradient-batch-theta-i}{{22}{27}{迭代法求解\relax }{equation.3.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces 二次曲线梯度下降算法示意图\relax }}{28}{figure.caption.16}}
\newlabel{f000014}{{14}{28}{二次曲线梯度下降算法示意图\relax \relax }{figure.caption.16}{}}
\newlabel{lrrn-parameter-update-formula}{{23}{28}{迭代法求解\relax }{equation.3.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}解析法求解}{28}{subsubsection.3.1.2}}
\newlabel{lrrn-scala-vector-gradient-def}{{24}{28}{解析法求解\relax }{equation.3.24}{}}
\newlabel{lrrn-vector-parameter-update-formula}{{25}{28}{解析法求解\relax }{equation.3.25}{}}
\newlabel{lrrn-function-matrix-parameter}{{26}{29}{解析法求解\relax }{equation.3.26}{}}
\newlabel{lrrn-function-matrix-parameter-gradient}{{27}{29}{解析法求解\relax }{equation.3.27}{}}
\newlabel{lrrn-matrix-tr-def}{{28}{29}{解析法求解\relax }{equation.3.28}{}}
\newlabel{lrrn-design-matrix-def}{{29}{29}{解析法求解\relax }{equation.3.29}{}}
\newlabel{lrrn-linear-regression-formula-in-design-matrix}{{30}{29}{解析法求解\relax }{equation.3.30}{}}
\newlabel{lrrn-linear-regression-formula-target-truth}{{31}{29}{解析法求解\relax }{equation.3.31}{}}
\newlabel{lrrn-vector-t-vector-mul}{{32}{30}{解析法求解\relax }{equation.3.32}{}}
\newlabel{lrrn-derive-loss-function}{{33}{30}{解析法求解\relax }{equation.3.33}{}}
\newlabel{lrrn-loss-function-in-vector}{{34}{30}{解析法求解\relax }{equation.3.34}{}}
\newlabel{lrrn-min-sq-mul}{{35}{30}{解析法求解\relax }{equation.3.35}{}}
\newlabel{lrrn-theta-star}{{36}{30}{解析法求解\relax }{equation.3.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}线性回归求解}{31}{subsection.3.2}}
\newlabel{lrrn-module-def}{{17}{31}{线性模型定义（resources/book/chp002/e1/linear\_regression\_model.py）\relax }{lstlisting.17}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {17}线性模型定义（resources/book/chp002/e1/linear\_regression\_model.py）}{31}{lstlisting.17}}
\newlabel{lrrn-lrrn-app}{{18}{32}{线性回归示例（resources/book/chp002/e1/linear\_regression\_app.py）\relax }{lstlisting.18}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {18}线性回归示例（resources/book/chp002/e1/linear\_regression\_app.py）}{32}{lstlisting.18}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces 线性回归运行结果\relax }}{33}{figure.caption.17}}
\newlabel{f000015}{{15}{33}{线性回归运行结果\relax \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}多项式回归}{34}{subsection.3.3}}
\newlabel{lrrn-taylor-formula}{{37}{34}{多项式回归\relax }{equation.3.37}{}}
\newlabel{lrrn-taylor-formula-x00}{{38}{34}{多项式回归\relax }{equation.3.38}{}}
\newlabel{lrrn-polynomial-regress-target-function}{{19}{34}{多项式回归示例（resources/book/chp002/e2/polynomial\_regression\_app.py）\relax }{lstlisting.19}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {19}多项式回归示例（resources/book/chp002/e2/polynomial\_regression\_app.py）}{34}{lstlisting.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces 多项式回归目标曲线图\relax }}{35}{figure.caption.18}}
\newlabel{f000016}{{16}{35}{多项式回归目标曲线图\relax \relax }{figure.caption.18}{}}
\newlabel{lrrn-polynomial-regression-app}{{20}{35}{多项式回归示例（resources/book/chp002/e2/polynomial\_regression\_app.py）\relax }{lstlisting.20}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {20}多项式回归示例（resources/book/chp002/e2/polynomial\_regression\_app.py）}{35}{lstlisting.20}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces 多项式回归最高次为1次运行结果图\relax }}{39}{figure.caption.19}}
\newlabel{f000017}{{17}{39}{多项式回归最高次为1次运行结果图\relax \relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces 多项式回归最高次为1次学习的参数值\relax }}{39}{figure.caption.20}}
\newlabel{f000018}{{18}{39}{多项式回归最高次为1次学习的参数值\relax \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces 多项式回归最高次为2次运行结果图\relax }}{39}{figure.caption.21}}
\newlabel{f000019}{{19}{39}{多项式回归最高次为2次运行结果图\relax \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces 多项式回归最高次为2次学习的参数值\relax }}{40}{figure.caption.22}}
\newlabel{f000020}{{20}{40}{多项式回归最高次为2次学习的参数值\relax \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces 多项式回归最高次为9次运行结果图\relax }}{40}{figure.caption.23}}
\newlabel{f000021}{{21}{40}{多项式回归最高次为9次运行结果图\relax \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces 多项式回归最高次为9次学习的参数值\relax }}{40}{figure.caption.24}}
\newlabel{f000022}{{22}{40}{多项式回归最高次为9次学习的参数值\relax \relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}总结}{40}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}逻辑回归概述}{41}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}数学基础}{41}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}直观解释}{41}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}数学推导}{41}{subsubsection.4.1.2}}
\newlabel{lcrn-hx-def}{{39}{42}{数学推导\relax }{equation.4.39}{}}
\newlabel{lcrn-sigmoid-function-def}{{40}{42}{数学推导\relax }{equation.4.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces sigmoid函数图像\relax }}{42}{figure.caption.25}}
\newlabel{f000023}{{23}{42}{sigmoid函数图像\relax \relax }{figure.caption.25}{}}
\newlabel{lcrn-sigmoid-gradient-formula}{{41}{42}{数学推导\relax }{equation.4.41}{}}
\newlabel{lcrn-z-def}{{42}{42}{数学推导\relax }{equation.4.42}{}}
\newlabel{lcrn-h-theta-def}{{43}{42}{数学推导\relax }{equation.4.43}{}}
\newlabel{lcrn-y0-y1-def}{{44}{42}{数学推导\relax }{equation.4.44}{}}
\newlabel{lcrn-y0-y1-merged}{{45}{43}{数学推导\relax }{equation.4.45}{}}
\newlabel{lcrn-likelyhood-function-def}{{46}{43}{数学推导\relax }{equation.4.46}{}}
\newlabel{lcrn-log-likelyhood-function-def}{{47}{43}{数学推导\relax }{equation.4.47}{}}
\newlabel{lcrn-log-likelyhood-function-simplified}{{48}{43}{数学推导\relax }{equation.4.48}{}}
\newlabel{lcrn-negative-log-likelyhood-function-simplified}{{49}{43}{数学推导\relax }{equation.4.49}{}}
\newlabel{lcrn-nll-gradient-symbol}{{50}{43}{数学推导\relax }{equation.4.50}{}}
\newlabel{lcrn-parameter-update-formala}{{51}{43}{数学推导\relax }{equation.4.51}{}}
\newlabel{lcrn-nll-vs-w-gradient-vector}{{52}{43}{数学推导\relax }{equation.4.52}{}}
\newlabel{lcrn-nll-vs-wj-gradient}{{53}{44}{数学推导\relax }{equation.4.53}{}}
\newlabel{lcrn-nll-vs-b-gradient}{{54}{44}{数学推导\relax }{equation.4.54}{}}
\newlabel{lcrn-wj-update}{{55}{45}{数学推导\relax }{equation.4.55}{}}
\newlabel{lcrn-b-update}{{56}{45}{数学推导\relax }{equation.4.56}{}}
\newlabel{lcrn-thetaj-update}{{57}{45}{数学推导\relax }{equation.4.57}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}牛顿法}{45}{subsubsection.4.1.3}}
\newlabel{lcrn-newton-method}{{58}{45}{牛顿法\relax }{equation.4.58}{}}
\newlabel{lcrn-newton-method-demo-function}{{59}{45}{牛顿法\relax }{equation.4.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces 过$x_{0}$点切线示意图\relax }}{46}{figure.caption.26}}
\newlabel{f000024}{{24}{46}{过$x_{0}$点切线示意图\relax \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces 过$x_{1}$点切线示意图\relax }}{47}{figure.caption.27}}
\newlabel{f000025}{{25}{47}{过$x_{1}$点切线示意图\relax \relax }{figure.caption.27}{}}
\newlabel{lcrn-newton-method-graph-draw}{{21}{47}{牛顿法求解示意图（app/pytorch/book/chp003/chp003\_c002.py）\relax }{lstlisting.21}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {21}牛顿法求解示意图（app/pytorch/book/chp003/chp003\_c002.py）}{47}{lstlisting.21}}
\newlabel{lcrn-nll-newton-method}{{60}{49}{牛顿法\relax }{equation.4.60}{}}
\newlabel{lcrn-theta-modified-for-newton-vector-method}{{61}{49}{牛顿法\relax }{equation.4.61}{}}
\newlabel{lcrn-x-modified-for-newton-vector-method}{{62}{49}{牛顿法\relax }{equation.4.62}{}}
\newlabel{lcrn-newton-vector-method}{{63}{49}{牛顿法\relax }{equation.4.63}{}}
\newlabel{lcrn-loss-theta-gradient}{{64}{49}{牛顿法\relax }{equation.4.64}{}}
\newlabel{lcrn-hessian-matrix-def}{{65}{49}{牛顿法\relax }{equation.4.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}通用学习模型}{50}{subsubsection.4.1.4}}
\newlabel{lcrn-linear-regression-def}{{66}{50}{通用学习模型\relax }{equation.4.66}{}}
\newlabel{lcrn-gaussian-uni-def}{{67}{50}{通用学习模型\relax }{equation.4.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces 一元高斯分布函数图像\relax }}{50}{figure.caption.28}}
\newlabel{f000026}{{26}{50}{一元高斯分布函数图像\relax \relax }{figure.caption.28}{}}
\newlabel{lcrn-lcrn-prob}{{68}{50}{通用学习模型\relax }{equation.4.68}{}}
\newlabel{lcrn-exp-function-group}{{69}{50}{通用学习模型\relax }{equation.4.69}{}}
\@writefile{toc}{\contentsline {paragraph}{逻辑回归推导}{51}{section*.29}}
\newlabel{lcrn-gml-bernulli}{{70}{51}{逻辑回归推导\relax }{equation.4.70}{}}
\newlabel{lcrn-gml-bernulli-pp}{{71}{51}{逻辑回归推导\relax }{equation.4.71}{}}
\newlabel{lcrn-gml-eta-def}{{72}{51}{逻辑回归推导\relax }{equation.4.72}{}}
\newlabel{lcrn-gml-eta-to-phi}{{73}{51}{逻辑回归推导\relax }{equation.4.73}{}}
\@writefile{toc}{\contentsline {paragraph}{线性回归}{51}{section*.30}}
\newlabel{lcrn-gml-linear-regression-derive}{{74}{51}{线性回归\relax }{equation.4.74}{}}
\@writefile{toc}{\contentsline {paragraph}{通用机器学习模型总结}{52}{section*.31}}
\newlabel{lcrn-gml-yhat}{{75}{52}{通用机器学习模型总结\relax }{equation.4.75}{}}
\newlabel{lcrn-gml-eta-vector-formula}{{76}{52}{通用机器学习模型总结\relax }{equation.4.76}{}}
\@writefile{toc}{\contentsline {subparagraph}{线性回归}{53}{section*.32}}
\newlabel{lcrn-gml-linear-regression-summary}{{77}{53}{线性回归\relax }{equation.4.77}{}}
\newlabel{lcrn-gml-linear-regression-summary-yhat}{{78}{53}{线性回归\relax }{equation.4.78}{}}
\newlabel{lcrn-gml-linear-regression-summary-theta-b}{{79}{53}{线性回归\relax }{equation.4.79}{}}
\newlabel{lcrn-gml-linear-regression-summary-x0}{{80}{53}{线性回归\relax }{equation.4.80}{}}
\@writefile{toc}{\contentsline {subparagraph}{逻辑回归}{53}{section*.33}}
\newlabel{lcrn-gml-logistic-regression-summary}{{81}{53}{逻辑回归\relax }{equation.4.81}{}}
\newlabel{lcrn-gml-yhat-deduction}{{82}{53}{逻辑回归\relax }{equation.4.82}{}}
\@writefile{toc}{\contentsline {paragraph}{softmax回归}{54}{section*.34}}
\newlabel{lcrn-multi-class-phi-sum}{{83}{54}{softmax回归\relax }{equation.4.83}{}}
\newlabel{lcrn-multi-class-P}{{84}{54}{softmax回归\relax }{equation.4.84}{}}
\newlabel{lcrn-multi-class-phi-K-deduction}{{85}{54}{softmax回归\relax }{equation.4.85}{}}
\newlabel{lcrn-multi-class-phi-ty-definition}{{86}{54}{softmax回归\relax }{equation.4.86}{}}
\newlabel{lcrn-multi-class-indicator-function}{{87}{54}{softmax回归\relax }{equation.4.87}{}}
\newlabel{lcrn-multi-class-indicator-function-ty}{{88}{54}{softmax回归\relax }{equation.4.88}{}}
\newlabel{lcrn-multi-class-indicator-function-ty-Ex}{{89}{54}{softmax回归\relax }{equation.4.89}{}}
\newlabel{lcrn-multi-class-indicator-function-ty-pp}{{90}{55}{softmax回归\relax }{equation.4.90}{}}
\newlabel{lcrn-gml-softmax-regression-params}{{91}{55}{softmax回归\relax }{equation.4.91}{}}
\newlabel{lcrn-softmax-regression-eta-deduction}{{92}{55}{softmax回归\relax }{equation.4.92}{}}
\newlabel{lcrn-softmax-regression-eta-deduction-1}{{93}{55}{softmax回归\relax }{equation.4.93}{}}
\newlabel{lcrn-softmax-regression-eta-deduction-2}{{94}{55}{softmax回归\relax }{equation.4.94}{}}
\newlabel{lcrn-softmax-regression-eta-deduction-3}{{95}{56}{softmax回归\relax }{equation.4.95}{}}
\newlabel{lcrn-softmax-regression-eta-deduction-4}{{96}{56}{softmax回归\relax }{equation.4.96}{}}
\newlabel{lcrn-softmax-regression-eta-deduction-5}{{97}{56}{softmax回归\relax }{equation.4.97}{}}
\newlabel{lcrn-softmax-regression-prop-p}{{98}{56}{softmax回归\relax }{equation.4.98}{}}
\newlabel{lcrn-softmax-regression-yhat}{{99}{56}{softmax回归\relax }{equation.4.99}{}}
\newlabel{lcrn-softmax-regression-item-K}{{100}{56}{softmax回归\relax }{equation.4.100}{}}
\newlabel{lcrn-softmax-regression-nll-1}{{101}{56}{softmax回归\relax }{equation.4.101}{}}
\newlabel{lcrn-softmax-regression-nll-2}{{102}{57}{softmax回归\relax }{equation.4.102}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}交叉熵函数}{57}{subsubsection.4.1.5}}
\@writefile{toc}{\contentsline {paragraph}{多分类问题}{57}{section*.35}}
\@writefile{toc}{\contentsline {subparagraph}{多分类问题的表示}{57}{section*.36}}
\newlabel{lcrg-multi-classification-one-hot}{{103}{57}{多分类问题的表示\relax }{equation.4.103}{}}
\newlabel{lcrg-mnist-y-hat-def}{{104}{57}{多分类问题的表示\relax }{equation.4.104}{}}
\newlabel{lcrn-bernulli-def}{{105}{57}{多分类问题的表示\relax }{equation.4.105}{}}
\@writefile{toc}{\contentsline {subparagraph}{信息论简介}{57}{section*.37}}
\newlabel{lcrn-self-information-def}{{106}{57}{信息论简介\relax }{equation.4.106}{}}
\newlabel{lcrn-shannon-entropy-def}{{107}{58}{信息论简介\relax }{equation.4.107}{}}
\newlabel{lcrn-kl-divergence-def}{{108}{58}{信息论简介\relax }{equation.4.108}{}}
\newlabel{lcrn-crossentropy-def}{{109}{58}{信息论简介\relax }{equation.4.109}{}}
\@writefile{toc}{\contentsline {subparagraph}{多分类问题交叉熵函数定义}{58}{section*.38}}
\newlabel{lcrn-mnist-crossentropy-def}{{110}{58}{多分类问题交叉熵函数定义\relax }{equation.4.110}{}}
\newlabel{lcrn-mnist-crossentropy-formula}{{111}{58}{多分类问题交叉熵函数定义\relax }{equation.4.111}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}二分类问题应用}{58}{subsection.4.2}}
\newlabel{lcrn-logistic-regression-bic-dataset-generation}{{22}{58}{生成学习数据（app/pytorch/book/chp003/e1/logistic\_regression\_app.py）\relax }{lstlisting.22}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {22}生成学习数据（app/pytorch/book/chp003/e1/logistic\_regression\_app.py）}{58}{lstlisting.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces 逻辑回归二分类数据集图\relax }}{60}{figure.caption.39}}
\newlabel{f000027}{{27}{60}{逻辑回归二分类数据集图\relax \relax }{figure.caption.39}{}}
\newlabel{lcrn-logistic-regression-model}{{23}{60}{逻辑回归模型类（app/pytorch/book/chp003/e1/logistic\_regression\_model.py）\relax }{lstlisting.23}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {23}逻辑回归模型类（app/pytorch/book/chp003/e1/logistic\_regression\_model.py）}{60}{lstlisting.23}}
\newlabel{lcrn-logistic-regression-train-model}{{24}{60}{二分类逻辑回归训练（app/pytorch/book/chp003/e1/logistic\_regression\_app.py）\relax }{lstlisting.24}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {24}二分类逻辑回归训练（app/pytorch/book/chp003/e1/logistic\_regression\_app.py）}{60}{lstlisting.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces 逻辑回归二分类学习结果（参数值）图\relax }}{62}{figure.caption.40}}
\newlabel{f000029}{{28}{62}{逻辑回归二分类学习结果（参数值）图\relax \relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces 逻辑回归二分类学习结果图\relax }}{62}{figure.caption.41}}
\newlabel{f000028}{{29}{62}{逻辑回归二分类学习结果图\relax \relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}softmax回归应用}{62}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}载入MNIST数据集}{62}{subsubsection.4.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces MNIST手写数字识别图片示例\relax }}{63}{figure.caption.42}}
\newlabel{f000030}{{30}{63}{MNIST手写数字识别图片示例\relax \relax }{figure.caption.42}{}}
\newlabel{lcrn-load-mnist-from-csv}{{25}{63}{通过预先下载的CSV文件载入MNIST数据集(app.pytorch.book.chp003.e2.logistic\_regression\_app.py)\relax }{lstlisting.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {25}通过预先下载的CSV文件载入MNIST数据集(app.pytorch.book.chp003.e2.logistic\_regression\_app.py)}{63}{lstlisting.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces MNIST手写数字识别单位样本示例\relax }}{66}{figure.caption.43}}
\newlabel{f000031}{{31}{66}{MNIST手写数字识别单位样本示例\relax \relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}MNIST数据集可视化}{66}{subsubsection.4.3.2}}
\newlabel{lcrn-mnist-tsne}{{26}{66}{t-sne可视化MNIST数据集\relax }{lstlisting.26}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {26}t-sne可视化MNIST数据集}{66}{lstlisting.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces MNIST数据集t-SNE图\relax }}{68}{figure.caption.44}}
\newlabel{f000032}{{32}{68}{MNIST数据集t-SNE图\relax \relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}代码实现}{68}{subsubsection.4.3.3}}
\newlabel{lcrn-softmax-regression-model}{{27}{68}{softmax回归模型类\relax }{lstlisting.27}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {27}softmax回归模型类}{68}{lstlisting.27}}
\newlabel{lcrn-softmax-regression-app}{{28}{69}{softmax回归代码实现\relax }{lstlisting.28}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {28}softmax回归代码实现}{69}{lstlisting.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces 运行结果后台输出\relax }}{71}{figure.caption.45}}
\newlabel{f000033}{{33}{71}{运行结果后台输出\relax \relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces 运行结果示意图\relax }}{71}{figure.caption.46}}
\newlabel{f000034}{{34}{71}{运行结果示意图\relax \relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}总结}{71}{subsection.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}多层感知器（MLP）概述}{73}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}数学原理}{73}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}前向传播过程}{73}{subsubsection.5.1.1}}
\newlabel{mlp-a-l-1}{{112}{74}{前向传播过程\relax }{equation.5.112}{}}
\newlabel{mlp-w-l-1-l}{{113}{74}{前向传播过程\relax }{equation.5.113}{}}
\newlabel{mlp-z-l-def}{{114}{74}{前向传播过程\relax }{equation.5.114}{}}
\newlabel{mlp-a-l-def}{{115}{74}{前向传播过程\relax }{equation.5.115}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}神经元激活函数}{74}{subsubsection.5.1.2}}
\@writefile{toc}{\contentsline {paragraph}{sigmoid函数}{74}{section*.47}}
\@writefile{toc}{\contentsline {subparagraph}{定义}{74}{section*.48}}
\newlabel{mlp-sigmoid-def}{{116}{74}{定义\relax }{equation.5.116}{}}
\newlabel{mlp-draw-sigmoid}{{29}{74}{绘制sigmoid函数\relax }{lstlisting.29}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {29}绘制sigmoid函数}{74}{lstlisting.29}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces sigmoid函数\relax }}{75}{figure.caption.49}}
\newlabel{f000035}{{35}{75}{sigmoid函数\relax \relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subparagraph}{导数}{75}{section*.50}}
\newlabel{mlp-sigmoid-devirative-math-def}{{117}{75}{导数\relax }{equation.5.117}{}}
\newlabel{mlp-devirative-formula-1}{{118}{75}{导数\relax }{equation.5.118}{}}
\newlabel{mlp-devirative-formula-2}{{119}{75}{导数\relax }{equation.5.119}{}}
\newlabel{mlp-devirative-formula-3}{{120}{75}{导数\relax }{equation.5.120}{}}
\newlabel{mlp-sigmoid-devirative-formula}{{121}{76}{导数\relax }{equation.5.121}{}}
\@writefile{toc}{\contentsline {paragraph}{ReLU函数}{76}{section*.51}}
\newlabel{mlp-relu-def}{{122}{76}{ReLU函数\relax }{equation.5.122}{}}
\newlabel{mlp-relu-def-1}{{123}{76}{ReLU函数\relax }{equation.5.123}{}}
\newlabel{mlp-code-draw-relu}{{30}{76}{绘制ReLU函数\relax }{lstlisting.30}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {30}绘制ReLU函数}{76}{lstlisting.30}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces ReLU函数图像\relax }}{76}{figure.caption.52}}
\newlabel{f000036}{{36}{76}{ReLU函数图像\relax \relax }{figure.caption.52}{}}
\citation{r000004}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}深度学习中的微分运算}{77}{subsubsection.5.1.3}}
\newlabel{mlp-lcrn-output-forward}{{124}{77}{深度学习中的微分运算\relax }{equation.5.124}{}}
\@writefile{toc}{\contentsline {paragraph}{数值法}{77}{section*.53}}
\newlabel{mlp-math-devirative-def}{{125}{77}{数值法\relax }{equation.5.125}{}}
\newlabel{mlp-math-devirative-def-fine}{{126}{77}{数值法\relax }{equation.5.126}{}}
\@writefile{toc}{\contentsline {paragraph}{公式法求微分}{77}{section*.54}}
\newlabel{mlp-math-devirative-formula}{{127}{77}{公式法求微分\relax }{equation.5.127}{}}
\@writefile{toc}{\contentsline {paragraph}{计算图法}{78}{section*.55}}
\newlabel{mlp-sigmoid-def2}{{128}{78}{计算图法\relax }{equation.5.128}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces 计算图基本形式\relax }}{78}{figure.caption.56}}
\newlabel{f000037}{{37}{78}{计算图基本形式\relax \relax }{figure.caption.56}{}}
\newlabel{mlp-sigmoid-cg-1}{{129}{78}{计算图法\relax }{equation.5.129}{}}
\newlabel{mlp-sigmoid-cg-2}{{130}{78}{计算图法\relax }{equation.5.130}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces 计算图基本形式\relax }}{78}{figure.caption.57}}
\newlabel{f000038}{{38}{78}{计算图基本形式\relax \relax }{figure.caption.57}{}}
\newlabel{mlp-sigmoid-cg-3}{{131}{78}{计算图法\relax }{equation.5.131}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces 计算图基本形式\relax }}{79}{figure.caption.58}}
\newlabel{f000039}{{39}{79}{计算图基本形式\relax \relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces 计算图基本形式\relax }}{79}{figure.caption.59}}
\newlabel{f000040}{{40}{79}{计算图基本形式\relax \relax }{figure.caption.59}{}}
\newlabel{mlp-sigmoid-cg-4}{{132}{79}{计算图法\relax }{equation.5.132}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces 计算图基本形式\relax }}{79}{figure.caption.60}}
\newlabel{f000041}{{41}{79}{计算图基本形式\relax \relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces 计算图基本形式\relax }}{80}{figure.caption.61}}
\newlabel{f000042}{{42}{80}{计算图基本形式\relax \relax }{figure.caption.61}{}}
\newlabel{mlp-sigmoid-cg-5}{{133}{80}{计算图法\relax }{equation.5.133}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces 计算图基本形式\relax }}{80}{figure.caption.62}}
\newlabel{f000043}{{43}{80}{计算图基本形式\relax \relax }{figure.caption.62}{}}
\newlabel{mlp-sigmoid-cg-6}{{134}{80}{计算图法\relax }{equation.5.134}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces 计算图基本形式\relax }}{81}{figure.caption.63}}
\newlabel{f000044}{{44}{81}{计算图基本形式\relax \relax }{figure.caption.63}{}}
\newlabel{mlp-sigmoid-cg-7}{{135}{81}{计算图法\relax }{equation.5.135}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces 计算图基本形式\relax }}{81}{figure.caption.64}}
\newlabel{f000045}{{45}{81}{计算图基本形式\relax \relax }{figure.caption.64}{}}
\newlabel{mlp-sigmoid-cg-8}{{136}{81}{计算图法\relax }{equation.5.136}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces 计算图基本形式\relax }}{82}{figure.caption.65}}
\newlabel{f000046}{{46}{82}{计算图基本形式\relax \relax }{figure.caption.65}{}}
\newlabel{mlp-sigmoid-cg-9}{{137}{82}{计算图法\relax }{equation.5.137}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces 计算图基本形式\relax }}{82}{figure.caption.66}}
\newlabel{f000047}{{47}{82}{计算图基本形式\relax \relax }{figure.caption.66}{}}
\newlabel{mlp-sigmoid-cg-10}{{138}{82}{计算图法\relax }{equation.5.138}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces 计算图基本形式\relax }}{83}{figure.caption.67}}
\newlabel{f000048}{{48}{83}{计算图基本形式\relax \relax }{figure.caption.67}{}}
\newlabel{mlp-sigmoid-cg-11}{{139}{83}{计算图法\relax }{equation.5.139}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces 计算图基本形式\relax }}{83}{figure.caption.68}}
\newlabel{f000049}{{49}{83}{计算图基本形式\relax \relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {paragraph}{自动微分}{83}{section*.69}}
\newlabel{mlp-sigmoid-cg-12}{{140}{84}{自动微分\relax }{equation.5.140}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces 自动微分\relax }}{84}{figure.caption.70}}
\newlabel{f000050}{{50}{84}{自动微分\relax \relax }{figure.caption.70}{}}
\newlabel{mlp-sigmoid-cg-13}{{141}{84}{自动微分\relax }{equation.5.141}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces 自动微分\relax }}{84}{figure.caption.71}}
\newlabel{f000051}{{51}{84}{自动微分\relax \relax }{figure.caption.71}{}}
\newlabel{mlp-sigmoid-cg-14}{{142}{84}{自动微分\relax }{equation.5.142}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces 自动微分\relax }}{85}{figure.caption.72}}
\newlabel{f000052}{{52}{85}{自动微分\relax \relax }{figure.caption.72}{}}
\newlabel{mlp-sigmoid-cg-15}{{143}{85}{自动微分\relax }{equation.5.143}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces 自动微分\relax }}{85}{figure.caption.73}}
\newlabel{f000053}{{53}{85}{自动微分\relax \relax }{figure.caption.73}{}}
\newlabel{mlp-sigmoid-cg-16}{{144}{85}{自动微分\relax }{equation.5.144}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces 自动微分\relax }}{85}{figure.caption.74}}
\newlabel{f000054}{{54}{85}{自动微分\relax \relax }{figure.caption.74}{}}
\newlabel{mlp-sigmoid-cg-17}{{145}{86}{自动微分\relax }{equation.5.145}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces 自动微分\relax }}{86}{figure.caption.75}}
\newlabel{f000055}{{55}{86}{自动微分\relax \relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces 自动微分\relax }}{86}{figure.caption.76}}
\newlabel{f000056}{{56}{86}{自动微分\relax \relax }{figure.caption.76}{}}
\newlabel{mlp-sigmoid-cg-18}{{146}{86}{自动微分\relax }{equation.5.146}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces 自动微分\relax }}{87}{figure.caption.77}}
\newlabel{f000057}{{57}{87}{自动微分\relax \relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces 自动微分\relax }}{87}{figure.caption.78}}
\newlabel{f000058}{{58}{87}{自动微分\relax \relax }{figure.caption.78}{}}
\newlabel{mlp-sigmoid-cg-19}{{147}{87}{自动微分\relax }{equation.5.147}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces 自动微分\relax }}{87}{figure.caption.79}}
\newlabel{f000059}{{59}{87}{自动微分\relax \relax }{figure.caption.79}{}}
\newlabel{mlp-sigmoid-cg-20}{{148}{88}{自动微分\relax }{equation.5.148}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces 自动微分\relax }}{88}{figure.caption.80}}
\newlabel{f000060}{{60}{88}{自动微分\relax \relax }{figure.caption.80}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}softmax和Cross Entropy}{88}{subsubsection.5.1.4}}
\@writefile{toc}{\contentsline {paragraph}{多分类问题的表示}{88}{section*.81}}
\newlabel{mlp-mnist-one-hot-vector}{{149}{88}{多分类问题的表示\relax }{equation.5.149}{}}
\newlabel{mlp-mnist-y-hat-def}{{150}{88}{多分类问题的表示\relax }{equation.5.150}{}}
\newlabel{mlp-bernulli-def}{{151}{88}{多分类问题的表示\relax }{equation.5.151}{}}
\@writefile{toc}{\contentsline {paragraph}{信息论简介}{89}{section*.82}}
\newlabel{mlp-self-information-def}{{152}{89}{信息论简介\relax }{equation.5.152}{}}
\newlabel{mlp-shannon-entropy-def}{{153}{89}{信息论简介\relax }{equation.5.153}{}}
\newlabel{mlp-kl-divergence-def}{{154}{89}{信息论简介\relax }{equation.5.154}{}}
\newlabel{mlp-crossentropy-def}{{155}{89}{信息论简介\relax }{equation.5.155}{}}
\@writefile{toc}{\contentsline {paragraph}{多分类问题的交叉熵表示}{89}{section*.83}}
\newlabel{mlp-mnist-crossentropy-def}{{156}{89}{多分类问题的交叉熵表示\relax }{equation.5.156}{}}
\newlabel{mlp-mnist-crossentropy-formula}{{157}{89}{多分类问题的交叉熵表示\relax }{equation.5.157}{}}
\@writefile{toc}{\contentsline {paragraph}{softmax求导}{90}{section*.84}}
\newlabel{mlp-mnist-loss-function-crossentropy}{{158}{90}{softmax求导\relax }{equation.5.158}{}}
\newlabel{mlp-pL-pyhat}{{159}{90}{softmax求导\relax }{equation.5.159}{}}
\newlabel{mlp-pyhat-pa2}{{160}{90}{softmax求导\relax }{equation.5.160}{}}
\newlabel{mlp-softmax-def-for-i-element}{{161}{90}{softmax求导\relax }{equation.5.161}{}}
\newlabel{mlp-softmax-devirative-i=j}{{162}{90}{softmax求导\relax }{equation.5.162}{}}
\newlabel{mlp-softmax-devirative-i!=j}{{163}{91}{softmax求导\relax }{equation.5.163}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}计算图简介}{91}{subsubsection.5.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces 神经网络计算图表示\relax }}{91}{figure.caption.85}}
\newlabel{f000061}{{61}{91}{神经网络计算图表示\relax \relax }{figure.caption.85}{}}
\@writefile{toc}{\contentsline {paragraph}{正向传播}{91}{section*.86}}
\newlabel{mlp-cg-forward-1}{{164}{91}{正向传播\relax }{equation.5.164}{}}
\newlabel{mlp-cg-forward-2}{{165}{91}{正向传播\relax }{equation.5.165}{}}
\newlabel{mlp-cg-forward-3}{{166}{91}{正向传播\relax }{equation.5.166}{}}
\newlabel{mlp-cg-forward-4}{{167}{91}{正向传播\relax }{equation.5.167}{}}
\newlabel{mlp-cg-forward-5}{{168}{91}{正向传播\relax }{equation.5.168}{}}
\@writefile{toc}{\contentsline {paragraph}{反向传播}{92}{section*.87}}
\newlabel{mlp-cg-backward-1}{{169}{92}{反向传播\relax }{equation.5.169}{}}
\newlabel{mlp-cg-backward-2}{{170}{92}{反向传播\relax }{equation.5.170}{}}
\newlabel{mlp-cg-backward-3}{{171}{92}{反向传播\relax }{equation.5.171}{}}
\newlabel{mlp-cg-backward-4}{{172}{92}{反向传播\relax }{equation.5.172}{}}
\newlabel{mlp-cg-backward-5}{{173}{92}{反向传播\relax }{equation.5.173}{}}
\newlabel{mlp-cg-backward-6}{{174}{93}{反向传播\relax }{equation.5.174}{}}
\newlabel{mlp-cg-backward-7}{{175}{93}{反向传播\relax }{equation.5.175}{}}
\newlabel{mlp-cg-backward-8}{{176}{93}{反向传播\relax }{equation.5.176}{}}
\newlabel{mlp-cg-backward-9}{{177}{93}{反向传播\relax }{equation.5.177}{}}
\newlabel{mlp-cg-backward-10}{{178}{93}{反向传播\relax }{equation.5.178}{}}
\newlabel{mlp-cg-backward-11}{{179}{93}{反向传播\relax }{equation.5.179}{}}
\newlabel{mlp-cg-backward-12}{{180}{93}{反向传播\relax }{equation.5.180}{}}
\newlabel{mlp-cg-backward-13}{{181}{94}{反向传播\relax }{equation.5.181}{}}
\newlabel{mlp-cg-backward-14}{{182}{94}{反向传播\relax }{equation.5.182}{}}
\newlabel{mlp-cg-backward-15}{{183}{94}{反向传播\relax }{equation.5.183}{}}
\@writefile{toc}{\contentsline {paragraph}{网络参数求微分}{94}{section*.88}}
\newlabel{mlp-cg-backward-16}{{184}{94}{网络参数求微分\relax }{equation.5.184}{}}
\newlabel{mlp-cg-backward-17}{{185}{94}{网络参数求微分\relax }{equation.5.185}{}}
\newlabel{mlp-cg-backward-18}{{186}{94}{网络参数求微分\relax }{equation.5.186}{}}
\newlabel{mlp-cg-backward-19}{{187}{94}{网络参数求微分\relax }{equation.5.187}{}}
\@writefile{toc}{\contentsline {paragraph}{梯度下降算法调参数}{94}{section*.89}}
\newlabel{mlp-cg-backward-20}{{188}{94}{梯度下降算法调参数\relax }{equation.5.188}{}}
\newlabel{mlp-cg-backward-21}{{189}{94}{梯度下降算法调参数\relax }{equation.5.189}{}}
\newlabel{mlp-cg-backward-22}{{190}{94}{梯度下降算法调参数\relax }{equation.5.190}{}}
\newlabel{mlp-cg-backward-23}{{191}{94}{梯度下降算法调参数\relax }{equation.5.191}{}}
\newlabel{mlp-cg-backward-24}{{192}{95}{梯度下降算法调参数\relax }{equation.5.192}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.6}Softmax层实现技术}{95}{subsubsection.5.1.6}}
\@writefile{toc}{\contentsline {paragraph}{在线学习}{95}{section*.90}}
\newlabel{mlp-cross-entropy-vector-def}{{193}{95}{在线学习\relax }{equation.5.193}{}}
\newlabel{mlp-pj-py-def}{{194}{95}{在线学习\relax }{equation.5.194}{}}
\newlabel{mlp-py-pz-def}{{195}{95}{在线学习\relax }{equation.5.195}{}}
\newlabel{mlp-pz-pW-def}{{196}{96}{在线学习\relax }{equation.5.196}{}}
\newlabel{mlp-pz-pb-def}{{197}{96}{在线学习\relax }{equation.5.197}{}}
\newlabel{mlp-pz-px-def}{{198}{96}{在线学习\relax }{equation.5.198}{}}
\newlabel{mlp-pj-pz-def}{{199}{96}{在线学习\relax }{equation.5.199}{}}
\newlabel{mlp-pj-pW-def}{{200}{97}{在线学习\relax }{equation.5.200}{}}
\newlabel{mlp-pj-pb-def}{{201}{97}{在线学习\relax }{equation.5.201}{}}
\newlabel{mlp-pj-px-def}{{202}{98}{在线学习\relax }{equation.5.202}{}}
\@writefile{toc}{\contentsline {paragraph}{批量学习}{98}{section*.91}}
\newlabel{mlp-mini-batch-X-def}{{203}{98}{批量学习\relax }{equation.5.203}{}}
\newlabel{mlp-Z-XWT}{{204}{98}{批量学习\relax }{equation.5.204}{}}
\newlabel{mlp-Y-hat-def}{{205}{98}{批量学习\relax }{equation.5.205}{}}
\newlabel{mlp-mini-batch-cross-entropy-def}{{206}{98}{批量学习\relax }{equation.5.206}{}}
\newlabel{mlp-pJ-PYhat-def}{{207}{99}{批量学习\relax }{equation.5.207}{}}
\newlabel{mlp-pYhat-pZ-def}{{208}{99}{批量学习\relax }{equation.5.208}{}}
\newlabel{mlp-pZ-pW-def}{{209}{100}{批量学习\relax }{equation.5.209}{}}
\newlabel{mlp-pZ-pb-def}{{210}{101}{批量学习\relax }{equation.5.210}{}}
\newlabel{mlp-pZ-pX-def}{{211}{101}{批量学习\relax }{equation.5.211}{}}
\newlabel{mlp-pJ-pZ-def}{{212}{102}{批量学习\relax }{equation.5.212}{}}
\newlabel{mlp-pJ-pW-def}{{213}{102}{批量学习\relax }{equation.5.213}{}}
\newlabel{mlp-pJ-pb-def}{{214}{102}{批量学习\relax }{equation.5.214}{}}
\newlabel{mlp-pJ-pX-def}{{215}{102}{批量学习\relax }{equation.5.215}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.7}ReLU层实现技术}{102}{subsubsection.5.1.7}}
\@writefile{toc}{\contentsline {paragraph}{在线学习}{103}{section*.92}}
\newlabel{mlp-relu-z-def}{{216}{103}{在线学习\relax }{equation.5.216}{}}
\newlabel{mlp-leaky-relu-z-yhat-def}{{217}{103}{在线学习\relax }{equation.5.217}{}}
\newlabel{mlp-leaky-relu-pj-py}{{218}{103}{在线学习\relax }{equation.5.218}{}}
\newlabel{mlp-leaky-relu-pj-pz-def}{{219}{103}{在线学习\relax }{equation.5.219}{}}
\newlabel{mlp-leaky-relu-pz-px-def}{{220}{103}{在线学习\relax }{equation.5.220}{}}
\newlabel{mlp-leaky-relu-pj-pz-def1}{{221}{103}{在线学习\relax }{equation.5.221}{}}
\newlabel{mlp-leaky-relu-pj-pW-def}{{222}{104}{在线学习\relax }{equation.5.222}{}}
\newlabel{mlp-leaky-relu-pj-pb-def}{{223}{104}{在线学习\relax }{equation.5.223}{}}
\newlabel{mlp-leaky-relu-pj-px-def}{{224}{105}{在线学习\relax }{equation.5.224}{}}
\@writefile{toc}{\contentsline {paragraph}{批量学习}{105}{section*.93}}
\newlabel{mlp-leaky-relu-X-def}{{225}{105}{批量学习\relax }{equation.5.225}{}}
\newlabel{mlp-leaky-relu-Z-def}{{226}{105}{批量学习\relax }{equation.5.226}{}}
\newlabel{mlp-leaky-relu-Y-def}{{227}{105}{批量学习\relax }{equation.5.227}{}}
\newlabel{mlp-leaky-relu-pJ-pA-def}{{228}{105}{批量学习\relax }{equation.5.228}{}}
\newlabel{mlp-leaky-relu-pA-pZ-def}{{229}{106}{批量学习\relax }{equation.5.229}{}}
\newlabel{mlp-leaky-relu-pZ-pW-def}{{230}{107}{批量学习\relax }{equation.5.230}{}}
\newlabel{mlp-leaky-relu-pZ-pb-def}{{231}{108}{批量学习\relax }{equation.5.231}{}}
\newlabel{mlp-leaky-relu-pZ-pX-def}{{232}{108}{批量学习\relax }{equation.5.232}{}}
\newlabel{mlp-leaky-relu-pJ-pZ-def}{{233}{109}{批量学习\relax }{equation.5.233}{}}
\newlabel{mlp-leaky-relu-pJ-pW-def}{{234}{109}{批量学习\relax }{equation.5.234}{}}
\newlabel{mlp-leaky-relu-pJ-pb-def}{{235}{109}{批量学习\relax }{equation.5.235}{}}
\newlabel{mlp-leaky-relu-pJ-pX-def}{{236}{110}{批量学习\relax }{equation.5.236}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Numpy实现技术}{110}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}MNIST数据集简介}{110}{subsubsection.5.2.1}}
\@writefile{toc}{\contentsline {paragraph}{载入MNIST数据集}{110}{section*.94}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces MNIST手写数字识别图片示例\relax }}{110}{figure.caption.95}}
\newlabel{f000030001}{{62}{110}{MNIST手写数字识别图片示例\relax \relax }{figure.caption.95}{}}
\newlabel{logistic-regression-load-mnist-from-csv}{{31}{111}{通过预先下载的CSV文件载入MNIST数据集\relax }{lstlisting.31}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {31}通过预先下载的CSV文件载入MNIST数据集}{111}{lstlisting.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces MNIST手写数字识别单位样本示例\relax }}{113}{figure.caption.96}}
\newlabel{f000031001}{{63}{113}{MNIST手写数字识别单位样本示例\relax \relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {paragraph}{MNIST数据集可视化}{114}{section*.97}}
\newlabel{mlp-mnist-tsne}{{32}{114}{t-sne可视化MNIST数据集\relax }{lstlisting.32}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {32}t-sne可视化MNIST数据集}{114}{lstlisting.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces MNIST数据集t-SNE图\relax }}{115}{figure.caption.98}}
\newlabel{f000032001}{{64}{115}{MNIST数据集t-SNE图\relax \relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}应用入口}{116}{subsubsection.5.2.2}}
\newlabel{mlp-application-entry-point}{{33}{116}{多层感知器（MLP）模型应用入口\relax }{lstlisting.33}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {33}多层感知器（MLP）模型应用入口}{116}{lstlisting.33}}
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces 多层感知器模型汇总信息\relax }}{119}{figure.caption.99}}
\newlabel{f000062}{{65}{119}{多层感知器模型汇总信息\relax \relax }{figure.caption.99}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces 多层感知器模型网络结构图\relax }}{120}{figure.caption.100}}
\newlabel{f000063001}{{66}{120}{多层感知器模型网络结构图\relax \relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces 在训练数据集和验证数据集上的误差曲线变化图\relax }}{120}{figure.caption.101}}
\newlabel{f000064}{{67}{120}{在训练数据集和验证数据集上的误差曲线变化图\relax \relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces 在测试数据集上的精度\relax }}{121}{figure.caption.102}}
\newlabel{f000065}{{68}{121}{在测试数据集上的精度\relax \relax }{figure.caption.102}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}多层感知器类}{121}{subsubsection.5.2.3}}
\newlabel{mlp-mnist-model-class-def}{{34}{121}{多层感知器（MLP）模型类定义\relax }{lstlisting.34}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {34}多层感知器（MLP）模型类定义}{121}{lstlisting.34}}
\@writefile{toc}{\contentsline {paragraph}{初始化}{123}{section*.103}}
\@writefile{toc}{\contentsline {paragraph}{添加层}{124}{section*.104}}
\@writefile{toc}{\contentsline {paragraph}{前向及反向传播}{124}{section*.105}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}神经网络层定义}{125}{subsubsection.5.2.4}}
\@writefile{toc}{\contentsline {paragraph}{Softmax层}{125}{section*.106}}
\newlabel{mlp-ces-layer-def}{{35}{125}{Softmax层类定义\relax }{lstlisting.35}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {35}Softmax层类定义}{125}{lstlisting.35}}
\newlabel{mlp-ces-layer-unittest}{{36}{127}{Softmax层类单元测试用例\relax }{lstlisting.36}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {36}Softmax层类单元测试用例}{127}{lstlisting.36}}
\newlabel{mlp-ces-layer-unittest-run-cmd}{{37}{128}{Softmax层类单元测试用例运行命令\relax }{lstlisting.37}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {37}Softmax层类单元测试用例运行命令}{128}{lstlisting.37}}
\newlabel{mlp-ces-layer-forward-pass-Z-def}{{237}{129}{Softmax层\relax }{equation.5.237}{}}
\newlabel{mlp-ces-layer-forward-pass-cross-entropy-def}{{238}{129}{Softmax层\relax }{equation.5.238}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces Softmax层前向传播测试用例运行结果\relax }}{129}{figure.caption.107}}
\newlabel{f000057001}{{69}{129}{Softmax层前向传播测试用例运行结果\relax \relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces Softmax层反向传播运行结果\relax }}{131}{figure.caption.108}}
\newlabel{f000068}{{70}{131}{Softmax层反向传播运行结果\relax \relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {paragraph}{LeakyReLU层}{131}{section*.109}}
\newlabel{mlp-fully-connect-leaky-relu-def}{{38}{131}{全连接加LeakyReLU层\relax }{lstlisting.38}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {38}全连接加LeakyReLU层}{131}{lstlisting.38}}
\newlabel{mlp-fully-connect-leaky-relu-unittest}{{39}{133}{全连接加LeakyReLU层测试用例\relax }{lstlisting.39}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {39}全连接加LeakyReLU层测试用例}{133}{lstlisting.39}}
\newlabel{mlp-leaky-relu-func-def}{{239}{135}{LeakyReLU层\relax }{equation.5.239}{}}
\newlabel{mlp-fclr-leaky-relu-unittest-run}{{40}{135}{运行LeakyReLU激活函数测试用例\relax }{lstlisting.40}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {40}运行LeakyReLU激活函数测试用例}{135}{lstlisting.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces 运行结果\relax }}{135}{figure.caption.110}}
\newlabel{f000069}{{71}{135}{运行结果\relax \relax }{figure.caption.110}{}}
\newlabel{mlp-fclr-forward-pass-unittest-run}{{41}{136}{运行前向传播测试用例\relax }{lstlisting.41}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {41}运行前向传播测试用例}{136}{lstlisting.41}}
\@writefile{lof}{\contentsline {figure}{\numberline {72}{\ignorespaces 前向传播测试用例运行结果\relax }}{136}{figure.caption.111}}
\newlabel{f000070}{{72}{136}{前向传播测试用例运行结果\relax \relax }{figure.caption.111}{}}
\newlabel{mlp-leaky-relu-gradient-unittest}{{240}{136}{LeakyReLU层\relax }{equation.5.240}{}}
\newlabel{mlp-leaky-relu-backward-pass-unittest-gi}{{241}{137}{LeakyReLU层\relax }{equation.5.241}{}}
\newlabel{ml-leaky-relu-backward-pass-unittest-ai}{{242}{137}{LeakyReLU层\relax }{equation.5.242}{}}
\newlabel{mlp-leaky-relu-backward-pass-gai}{{243}{137}{LeakyReLU层\relax }{equation.5.243}{}}
\newlabel{mlp-leaky-relu-backward-pass-gvw}{{244}{137}{LeakyReLU层\relax }{equation.5.244}{}}
\newlabel{ml-leaky-relu-backward-pass-gai-xi}{{245}{137}{LeakyReLU层\relax }{equation.5.245}{}}
\citation{r000005}
\newlabel{mlp-fclr-backward-pass-unittest-run}{{42}{138}{运行前向传播测试用例\relax }{lstlisting.42}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {42}运行前向传播测试用例}{138}{lstlisting.42}}
\@writefile{lof}{\contentsline {figure}{\numberline {73}{\ignorespaces 前向传播测试用例运行结果\relax }}{138}{figure.caption.112}}
\newlabel{f000071}{{73}{138}{前向传播测试用例运行结果\relax \relax }{figure.caption.112}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}优化器}{138}{subsubsection.5.2.5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Adam算法\relax }}{139}{algorithm.1}}
\newlabel{mlp-adam-algorithm}{{1}{139}{Adam算法\relax \relax }{algorithm.1}{}}
\newlabel{mlp-adam-code}{{43}{139}{Adam算法实现\relax }{lstlisting.43}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {43}Adam算法实现}{139}{lstlisting.43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.6}训练过程}{140}{subsubsection.5.2.6}}
\@writefile{toc}{\contentsline {paragraph}{多层感知器类}{140}{section*.113}}
\newlabel{mlp-mlp-model-def}{{44}{140}{多层感知器模型类\relax }{lstlisting.44}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {44}多层感知器模型类}{140}{lstlisting.44}}
\@writefile{toc}{\contentsline {paragraph}{多层感知器应用}{145}{section*.114}}
\newlabel{mlp-mlp-app-def}{{45}{145}{多层感知器模型应用类\relax }{lstlisting.45}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {45}多层感知器模型应用类}{145}{lstlisting.45}}
\@writefile{lof}{\contentsline {figure}{\numberline {74}{\ignorespaces 训练精度变化图\relax }}{149}{figure.caption.115}}
\newlabel{f000072}{{74}{149}{训练精度变化图\relax \relax }{figure.caption.115}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.7}预测过程}{149}{subsubsection.5.2.7}}
\@writefile{toc}{\contentsline {paragraph}{序列化和反序列化}{149}{section*.116}}
\newlabel{mlp-pickle-params-save-demo}{{46}{149}{pickle模块应用示例\relax }{lstlisting.46}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {46}pickle模块应用示例}{149}{lstlisting.46}}
\@writefile{lof}{\contentsline {figure}{\numberline {75}{\ignorespaces 保存和恢复模型参数运行结果\relax }}{151}{figure.caption.117}}
\newlabel{f000063}{{75}{151}{保存和恢复模型参数运行结果\relax \relax }{figure.caption.117}{}}
\@writefile{toc}{\contentsline {paragraph}{预测方法实现}{151}{section*.118}}
\newlabel{mlp-app-predict}{{47}{151}{预测方式实现\relax }{lstlisting.47}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {47}预测方式实现}{151}{lstlisting.47}}
\newlabel{mlp-model-predict-save}{{48}{152}{预测、保存模型方法\relax }{lstlisting.48}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {48}预测、保存模型方法}{152}{lstlisting.48}}
\newlabel{mlp-fclr-save-restor-model}{{49}{152}{全连接层模型保存和恢复\relax }{lstlisting.49}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {49}全连接层模型保存和恢复}{152}{lstlisting.49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}PyTorch方法}{153}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}载入数据集}{154}{subsubsection.5.3.1}}
\newlabel{mlp-fclr-save-restor-model}{{50}{154}{利用torchvision载入手写数字识别MNIST数据集\relax }{lstlisting.50}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {50}利用torchvision载入手写数字识别MNIST数据集}{154}{lstlisting.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {76}{\ignorespaces 显示MNIST样本图像\relax }}{156}{figure.caption.119}}
\newlabel{f000074}{{76}{156}{显示MNIST样本图像\relax \relax }{figure.caption.119}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}模型定义}{156}{subsubsection.5.3.2}}
\newlabel{mlp-pytorch-mlp-model}{{51}{156}{多层感知器（MLP）模型类\relax }{lstlisting.51}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {51}多层感知器（MLP）模型类}{156}{lstlisting.51}}
\@writefile{lof}{\contentsline {figure}{\numberline {77}{\ignorespaces 网络架构图\relax }}{157}{figure.caption.120}}
\newlabel{f000075}{{77}{157}{网络架构图\relax \relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}训练和预测过程}{157}{subsubsection.5.3.3}}
\newlabel{mlp-pytorch-mlp-train-predict}{{52}{158}{多层感知器（MLP）训练和预测\relax }{lstlisting.52}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {52}多层感知器（MLP）训练和预测}{158}{lstlisting.52}}
\@writefile{lof}{\contentsline {figure}{\numberline {78}{\ignorespaces 训练模式输出\relax }}{162}{figure.caption.121}}
\newlabel{f000078}{{78}{162}{训练模式输出\relax \relax }{figure.caption.121}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {79}{\ignorespaces 预测模式输出\relax }}{162}{figure.caption.122}}
\newlabel{f000076}{{79}{162}{预测模式输出\relax \relax }{figure.caption.122}{}}
\citation{pytorch-nn-in-detail1}
\@writefile{lof}{\contentsline {figure}{\numberline {80}{\ignorespaces 预测样本图像\relax }}{163}{figure.caption.123}}
\newlabel{f000077}{{80}{163}{预测样本图像\relax \relax }{figure.caption.123}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}PyTorch核心原理}{163}{subsection.5.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}载入数据集}{163}{subsubsection.5.4.1}}
\newlabel{mlp-pytorch-load-mnist}{{53}{163}{载入数据集\relax }{lstlisting.53}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {53}载入数据集}{163}{lstlisting.53}}
\@writefile{toc}{\contentsline {section}{\numberline {6}卷积神经网络概述}{165}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}递归神经网络概述}{166}{section.7}}
\bibstyle{plainnat}
\bibdata{nips}
\bibcite{dl-tf-theano}{{1}{2017}{{闫涛，周琦}}{{}}}
\bibcite{csdn-blog-my-tensor1}{{2}{2019}{{最老程序员}}{{}}}
\bibcite{deep-learning-with-pytorch}{{3}{2019}{{Eli~Stevens}}{{}}}
\bibcite{pytorch-tensor-intro}{{4}{2019}{{facebook}}{{}}}
\bibcite{pytorch-nn-in-detail1}{{5}{2019}{{Howard}}{{}}}
